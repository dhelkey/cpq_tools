{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPQCC Processing Script - Processing the CPQCC key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformatted_output.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Parse the Excel file and write the output.\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m parsed_df \u001b[38;5;241m=\u001b[39m read_and_parse_excel(input_file_path)\n\u001b[0;32m     68\u001b[0m write_to_excel(parsed_df, output_file_path)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsed sections and written to\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_file_path)\n",
      "Cell \u001b[1;32mIn[1], line 48\u001b[0m, in \u001b[0;36mread_and_parse_excel\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     46\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(file_path, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m data_rows \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m---> 48\u001b[0m parsed_df \u001b[38;5;241m=\u001b[39m parse_sections(data_rows)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parsed_df\n",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m, in \u001b[0;36mparse_sections\u001b[1;34m(data_rows)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data_rows:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Check for the row that contains 'Variable Name', indicating the start of actual data\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariable Name\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m row:\n\u001b[1;32m---> 20\u001b[0m         column_names \u001b[38;5;241m=\u001b[39m [cell\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m row \u001b[38;5;28;01mif\u001b[39;00m cell \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     21\u001b[0m         column_names\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSection\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Add 'Section' to column names\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         column_names_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data_rows:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Check for the row that contains 'Variable Name', indicating the start of actual data\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariable Name\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m row:\n\u001b[1;32m---> 20\u001b[0m         column_names \u001b[38;5;241m=\u001b[39m [cell\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m row \u001b[38;5;28;01mif\u001b[39;00m cell \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     21\u001b[0m         column_names\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSection\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Add 'Section' to column names\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         column_names_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_sections(data_rows):\n",
    "    \"\"\"Parse data rows to identify sections, assign them to records, and correctly handle column names.\n",
    "\n",
    "    Args:\n",
    "        data_rows (list): List of tuples or lists representing rows from the Excel file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with correct columns and an added 'Section' column.\n",
    "    \"\"\"\n",
    "    section = None\n",
    "    parsed_data = []\n",
    "    column_names_found = False\n",
    "    column_names = []\n",
    "\n",
    "    for row in data_rows:\n",
    "        # Check for the row that contains 'Variable Name', indicating the start of actual data\n",
    "        if 'Variable Name' in row:\n",
    "            column_names = [cell.strip() for cell in row if cell is not None]\n",
    "            column_names.append('Section')  # Add 'Section' to column names\n",
    "            column_names_found = True\n",
    "            continue  # Skip this row in the output\n",
    "\n",
    "        if column_names_found:\n",
    "            # Assign section based on row content\n",
    "            if str(row[0]).startswith('Section'):\n",
    "                section = str(row[0]).strip()\n",
    "            else:\n",
    "                # Clean row data and append section\n",
    "                parsed_row = [str(cell).strip() if cell is not None else '' for cell in row]\n",
    "                parsed_row.append(section if section else 'Undefined')  # Add section info\n",
    "                parsed_data.append(parsed_row)\n",
    "    \n",
    "    return pd.DataFrame(parsed_data, columns=column_names)\n",
    "\n",
    "def read_and_parse_excel(file_path):\n",
    "    \"\"\"Read an Excel file, identify the start of actual data, and parse it to include a 'Section' column.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The file path to the Excel document.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The parsed DataFrame including sections.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path, header=None)\n",
    "    data_rows = df.values.tolist()\n",
    "    parsed_df = parse_sections(data_rows)\n",
    "    \n",
    "    return parsed_df\n",
    "\n",
    "def write_to_excel(df, output_file_path):\n",
    "    \"\"\"Write the DataFrame to an Excel file.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to write to Excel.\n",
    "        output_file_path (str): Path for the output Excel file.\n",
    "    \"\"\"\n",
    "    df.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Path to the input Excel file.\n",
    "input_file_path = 'CPQCC_Documentation_08152019.xlsx'\n",
    "# Path for the output Excel file.\n",
    "output_file_path = 'formatted_output.xlsx'\n",
    "\n",
    "# Parse the Excel file and write the output.\n",
    "parsed_df = read_and_parse_excel(input_file_path)\n",
    "write_to_excel(parsed_df, output_file_path)\n",
    "\n",
    "print(\"Parsed sections and written to\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "6 columns passed, passed data had 7 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:934\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 934\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:981\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    984\u001b[0m     )\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 6 columns passed, passed data had 7 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformatted_output.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Parse the Excel file and write the output.\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m parsed_df \u001b[38;5;241m=\u001b[39m read_and_parse_excel(input_file_path)\n\u001b[0;32m     63\u001b[0m write_to_excel(parsed_df, output_file_path)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsed sections and written to\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_file_path)\n",
      "Cell \u001b[1;32mIn[5], line 43\u001b[0m, in \u001b[0;36mread_and_parse_excel\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Convert DataFrame to a list of rows for parsing.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m data_rows \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m---> 43\u001b[0m parsed_df \u001b[38;5;241m=\u001b[39m parse_sections(data_rows)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parsed_df\n",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m, in \u001b[0;36mparse_sections\u001b[1;34m(data_rows)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Assuming the first non-section row can be used to derive column names.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m column_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariable Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mField Type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRange of Possible Values\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCoding Rules\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSection\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(parsed_data, columns\u001b[38;5;241m=\u001b[39mcolumn_names)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:782\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 782\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    783\u001b[0m         \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[0;32m    785\u001b[0m         data,\n\u001b[0;32m    786\u001b[0m         columns,\n\u001b[0;32m    787\u001b[0m         index,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    788\u001b[0m         dtype,\n\u001b[0;32m    789\u001b[0m     )\n\u001b[0;32m    790\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    791\u001b[0m         arrays,\n\u001b[0;32m    792\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    795\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    796\u001b[0m     )\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:498\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[1;32m--> 498\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m to_arrays(data, columns, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    499\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:840\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    837\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    838\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m--> 840\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:937\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    934\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m    940\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: 6 columns passed, passed data had 7 columns"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_sections(data_rows):\n",
    "    \"\"\"Parse data rows to identify sections and assign them to records.\n",
    "\n",
    "    Args:\n",
    "        data_rows (list): List of tuples or lists representing rows from the Excel file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an added 'Section' column.\n",
    "    \"\"\"\n",
    "    section = None\n",
    "    parsed_data = []\n",
    "    \n",
    "    for row in data_rows:\n",
    "        # Identify a section row. Sections are assumed to start with 'Section' keyword.\n",
    "        if str(row[0]).startswith('Section'):\n",
    "            section = row[0]\n",
    "        else:\n",
    "            # Retain the original row and append the current section to it.\n",
    "            parsed_row = list(row) + [section if section else 'Undefined']\n",
    "            parsed_data.append(parsed_row)\n",
    "    \n",
    "    # Assuming the first non-section row can be used to derive column names.\n",
    "    column_names = ['Variable Name', 'Description', 'Field Type', 'Range of Possible Values', 'Coding Rules', 'Section']\n",
    "    return pd.DataFrame(parsed_data, columns=column_names)\n",
    "\n",
    "def read_and_parse_excel(file_path):\n",
    "    \"\"\"Read an Excel file and parse it to include a 'Section' column.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The file path to the Excel document.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The parsed DataFrame including sections.\n",
    "    \"\"\"\n",
    "    # Read the Excel file, skipping rows until the header is found.\n",
    "    df = pd.read_excel(file_path, header=None)\n",
    "    \n",
    "    # Convert DataFrame to a list of rows for parsing.\n",
    "    data_rows = df.values.tolist()\n",
    "    \n",
    "    parsed_df = parse_sections(data_rows)\n",
    "    \n",
    "    return parsed_df\n",
    "\n",
    "def write_to_excel(df, output_file_path):\n",
    "    \"\"\"Write the DataFrame to an Excel file.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to write to Excel.\n",
    "        output_file_path (str): Path for the output Excel file.\n",
    "    \"\"\"\n",
    "    df.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Path to the input Excel file.\n",
    "input_file_path = 'CPQCC_Documentation_08152019.xlsx'\n",
    "# Path for the output Excel file.\n",
    "output_file_path = 'formatted_output.xlsx'\n",
    "\n",
    "# Parse the Excel file and write the output.\n",
    "parsed_df = read_and_parse_excel(input_file_path)\n",
    "write_to_excel(parsed_df, output_file_path)\n",
    "\n",
    "print(\"Parsed sections and written to\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ntpath' (frozen)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhelkey/.bashrc: line 3: alias: znn: not found\n",
      "/home/dhelkey/.bashrc: line 3: alias: =./znn-cli: not found\n",
      "/home/dhelkey/.bashrc: line 15: bind: warning: line editing not enabled\n",
      "/home/dhelkey/.bashrc: line 16: bind: warning: line editing not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~$birth_key.xlsx\n",
      "birth_key.xlsx\n",
      "CPQCC_Documentation_08152019.xlsx\n",
      "create_datasets.py\n",
      "data_helper_functions.py\n",
      "__init__.py\n",
      "PROCESS_CPQCC.ipynb\n",
      "PROCESS_PENN.ipynb\n",
      "__pycache__\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metadata processing\n",
    "#Generate excel variable file from documentation file\n",
    "# (e.g. label sections, remove spaces)\n",
    "\n",
    "#Performed once, on each raw file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
